{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# Learning Apache Spark · PySpark\n",
    "\n",
    "Apache Spark is an open-source cluster-computing framework. Spark Core is the foundation of the overall project. It is exposed by three APIs (Java, Scala and Python). In this book we will present the Python API called Pyspark.\n",
    "\n",
    "![Contexto de Spark](../images/slide1.png \"Contexto de Spark\")\n",
    "\n",
    "## 0 · Spark's Workflow\n",
    "Once the driver triggers an **action** on a RDD (we'll see later what those concepts are).\n",
    "* Spark submits a **Job**, which is formed by basic work units called **tasks** (*one per RDD partition*)  \n",
    "* **Tasks** are executed in parallel, one per partition of a single RDD, which form a **Stage**. (*Physical Unit of Execution*)\n",
    "* A **job** can be made of one or more **stages**, organized in DAG (*Directed Acyclic Graphs*).\n",
    "![Jobs](../images/slide2.png)\n",
    "![Stages](../images/slide3.png)\n",
    "\n",
    "## 1 · Open the Spark Context\n",
    "First of all, we have to create a **SparkContext** object, which is the ***entry point*** to the Spark cluster. The driver hosts the SparkContext.\n",
    "We can set the Spark Application Configuration by **SparkConf** object. For the moment we are going to set just two parameters,  \n",
    "1. **AppName**: Application Name\n",
    "2. **Master**: Cluster's master URL  \n",
    " * ***'local'***: Connect to localhost with just one worker. No parallelization at all.\n",
    " * ***'local[***\\****]'***: Connect to localhost with as many workers as cores on our machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "conf = pyspark.SparkConf().setAppName('MiPrimeraSparkApp').setMaster('local[*]') #Creamos la configuración\n",
    "sc = pyspark.SparkContext(conf = conf) #Abrimos el contexto de Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Spark WebUI\n",
    "We have just started the session locally. Let's connect to the port 4040, configured by default by the SparkConf as the WebUI. In this interface we can navigate through:\n",
    "* Jobs\n",
    "* Stages\n",
    "* Environment\n",
    "* Executors  \n",
    "  \n",
    "We could change the webUI port with *spark.ui.port* parameter, e.g. ***SparkConf.set(\"spark.ui.port\",\"8080\")***.\n",
    "![SparkwebUI](../images/SparkwebUI.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## 2 · RDDs: Resilient Distributed Datasets\n",
    "The basic data structure in Spark is called RDD, **Resilient Distributed Dataset**. They are data collections that can be operated in parallel. Collections are cutted into **partitions** and distributed among the **worker nodes**. We can parallelize data collections using different methods.\n",
    "### Internal Structures\n",
    "1. **.parallelize(** **):** Python collections, such as ***lists*** or ***tuples***\n",
    "2. **.range(start, end = None,step = 1, numSlices = None):** It creates an ***integer RDD*** which contains elements from start to end, increased by step every element. If it is called with a single argument, start is set to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pepa', '1812-03-19', 20, True]\n",
      "['cat', 'elephant', 'rat', 'rat', 'cat']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ['Pepa','1812-03-19',20,True]\n",
    "\n",
    "distributedData = sc.parallelize(data)\n",
    "print(distributedData.collect())\n",
    "\n",
    "wordsList = ['cat', 'elephant', 'rat', 'rat', 'cat']\n",
    "wordsRDD = sc.parallelize(wordsList, 5)\n",
    "# numSlices=5, RDD's partition number\n",
    "print(wordsRDD.collect())\n",
    "\n",
    "wordsRDD.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secuencia = sc.range(2,12,2)\n",
    "secuencia.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### External Structures\n",
    "1. **.textFile(name, minPartitions=None, use_unicode=True):** It creates a ***string RDD*** from a ***text file***\n",
    "2. **.pickleFile(name, minPartitions=None):** It loads an RDD previously saved using ***.saveAsPickleFile()***\n",
    "3. **.hadoopFile(** **):**\n",
    "  \n",
    "#### Recap. Data formats.\n",
    "1. **Archivos de texto:** \n",
    "    * Delimited and readable text files\n",
    "    * Inefficient reading\n",
    "    * It does not support compression\n",
    "2. **SequenceFile:** \n",
    "    * Binary data structure for key-value pairs datasets\n",
    "    * *Row-based*\n",
    "3. **Apache (Hadoop Distributed File System)**\n",
    "    1. **Avro:** \n",
    "        * *Row-based*, binary and compact data format\n",
    "        * Based on JSON embedded schemas \n",
    "    2. **Parquet:** \n",
    "        * *Column-based*, binary data format\n",
    "        * Based on embedded schema\n",
    "        * Structure based on row groups (50Mb < row.group < 1Gb) and column chunk.\n",
    "        * It supports compression\n",
    "  \n",
    "![EstructuraDatos](../images/avroparquet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Project Gutenberg EBook of The Complete Works of William Shakespeare, by',\n",
       " 'William Shakespeare',\n",
       " '',\n",
       " 'This eBook is for the use of anyone anywhere at no cost and with',\n",
       " 'almost no restrictions whatsoever.  You may copy it, give it away or']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Shakespeare = sc.textFile(\"../data/shakespeare.txt\",1) #minPartitions=1\n",
    "Shakespeare.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 'aa'), (1, 'a'), (3, 'aaa')]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(1, 4)).map(lambda x: (x, \"a\" * x)) # Para entender los pair RDD, muévase más adelante.\n",
    "\n",
    "rdd.saveAsSequenceFile(\"../data/sequencefile\")\n",
    "rddseqFile = sc.sequenceFile(\"../data/sequencefile\")\n",
    "\n",
    "print(rddseqFile.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1812-03-19', 20, 'Pepa', True]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distributedData.saveAsPickleFile(\"../data/picklefile\", 5) # El 5 corresponde al número mínimo de particiones.\n",
    "secuenciaRecuperada = sc.pickleFile(\"../data/picklefile\",3)\n",
    "\n",
    "secuenciaRecuperada.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos el directorio previamente creado.\n",
    "import shutil\n",
    "shutil.rmtree(\"../data/picklefile\",True)\n",
    "shutil.rmtree(\"../data/sequencefile\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "##### Apache Hadoop formats reading\n",
    "**Avro** and **parquet** are structured data files. For this reason, it's convenient to read and modify them by SparSQL module. We will focus on SparkSQL during the next session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### RDD Operations\n",
    "RDDs support two types of operations,\n",
    "1. **Transformations:** \n",
    "    * A **new RDD** is created from an existing one\n",
    "    * Transformations are ***lazy***. Computations are not executed when they are submited \n",
    "    * Instead, RDDs ***remember*** transformations previously applied on them\n",
    "2. **Actions:** They **return a result** to the driver after computations are done.  \n",
    "\n",
    "####  Passing functions to Spark\n",
    "Spark supports using functions in three different ways,\n",
    "1. **lambda** expressions\n",
    "2. Declared local functions **(def)**\n",
    "3. Functions included in any **module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cats', 'elephants', 'rats', 'rats', 'cats']\n"
     ]
    }
   ],
   "source": [
    "# 1. Lambda expressions\n",
    "pluralLambdaRDD = wordsRDD.map(lambda x: x + 's')\n",
    "print (pluralLambdaRDD.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cats\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cats', 'elephants', 'rats', 'rats', 'cats']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. local functions\n",
    "def makePlural(word):\n",
    "    return word + 's'\n",
    "\n",
    "print(makePlural('cat'))\n",
    "wordsRDD.map(makePlural).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'elephant', 'rat', 'rat', 'cat']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def makeSingular(word):\n",
    "    return word[:-1]\n",
    "\n",
    "pluralLambdaRDD.map(makeSingular).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 2, 1, 14, 13, 11, 7, 1, 11, 11]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    def SepararPalabras(s):\n",
    "        words = s.split(\" \")\n",
    "        return len(words)\n",
    "\n",
    "ShakWord = Shakespeare.map(SepararPalabras)\n",
    "ShakWord.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-12, -2, -1, -14, -13, -11, -7, -1, -11, -11]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Functions from modules\n",
    "from operator import neg,is_\n",
    "\n",
    "NegativeWords = ShakWord.map(neg)\n",
    "NegativeWords.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**is_(a,b)** is a function with ***two arguments*** which returns True or False depending on the equality or inequality between a and b.  \n",
    "This function can not be called through .map() function, due to the multiple input. First, we have to modify the function call. To do this, we mask the call with a new function with just one argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, True, False, False, False, False, True, False, False, False]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Is_(b):\n",
    "    def _is_(dataline):\n",
    "        return is_(dataline,b)\n",
    "    return _is_\n",
    "\n",
    "IsEqualToOne = NegativeWords.map(Is_(-1))\n",
    "IsEqualToOne.take(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 9, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "pluralLengths = (pluralLambdaRDD.map(lambda x: len(x)).collect())\n",
    "print( pluralLengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## 3 · Pair RDDs: Key-Value Pairs\n",
    "Pair RDDs are formed by key-value pair objects. In Python, they are built by parallelizing **tuples**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (2, 3), (2, 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listaDeTuples = [(1,2),(2,3),(2,1)]\n",
    "unPairRDD = sc.parallelize(listaDeTuples)\n",
    "unPairRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 1]\n",
      "[1, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(unPairRDD.values().collect()) # Show pairRDD values\n",
    "print(unPairRDD.keys().collect()) # Show pairRDD keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Transformations\n",
    "Common transformations supported by Spark.\n",
    "##### map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = Shakespeare.map(lambda s: (s, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "##### reduceByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pairs.reduceByKey(lambda a, b: a + b)\n",
    "# reduceByKey: It combines same key values applying a function to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "##### sortByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountsOrdered = counts.sortByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "##### flatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeareWords = Shakespeare.flatMap(lambda x: x.split(' '))\n",
    "# Similar to .map() but it can return multiple values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "##### union, intersection y distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3]\n",
      "[1, 2, 3, 2, 3, 4, 5]\n",
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "conjunto1RDD = sc.parallelize([1, 2, 3])\n",
    "conjunto2RDD = sc.parallelize([2, 3, 4, 5])\n",
    "\n",
    "print(conjunto1RDD.intersection(conjunto2RDD).collect())\n",
    "\n",
    "print(conjunto1RDD.union(conjunto2RDD).collect())\n",
    "\n",
    "print(conjunto1RDD.union(conjunto2RDD).distinct().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "##### filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "conjunto3RDD = sc.parallelize([8,7,5,4,1,1,7,2,5])\n",
    "conjunto3filtrado = conjunto3RDD.filter(lambda x:x>1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Actions\n",
    "##### first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('The Project Gutenberg EBook of The Complete Works of William Shakespeare, by',\n",
       " 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pairs = Shakespeare.map(lambda s: (s, 1))\n",
    "pairs.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "##### take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": 9679\n",
      "    May be call'd ransom, let it come. Sufficeth: 1\n",
      "    God, it holds yet.: 1\n",
      "  STEPHANO. Here; swear then how thou escap'dst.: 1\n",
      "    She is delivered, lord; she is delivered.: 1\n",
      "    I fear our purpose is discovered.: 1\n",
      "    Nay, and you shall hear some.  [To BRUTUS] Will you be gone?: 1\n",
      "  PAROLLES. It is to be recovered. But that the merit of service is: 1\n"
     ]
    }
   ],
   "source": [
    "# counts = pairs.reduceByKey(lambda a, b: a + b)\n",
    "for key, value in counts.take(8):\n",
    "    print ('{}: {}'.format(key, str(value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 9679),\n",
       " (\"                                                          'Goneril.'\", 1),\n",
       " ('                                                          Exeunt', 45),\n",
       " ('                                                          Exit GURNEY', 1),\n",
       " ('                                                          Guns heard.', 1),\n",
       " (\"                                                          HAMLET.'\", 1),\n",
       " ('                                                          Music.', 1),\n",
       " ('                                                          [Dies]', 3),\n",
       " ('                                                         Exeunt LORDS', 1),\n",
       " ('                                                         Exeunt.', 56)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountsOrdered = counts.sortByKey()\n",
    "CountsOrdered.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "##### takeSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('    eloquence in a sugar touch of them than in the tongues of the', 1),\n",
       " ('  JULIA. You mistake; the musician likes me not.', 1),\n",
       " ('  THIRD SOLDIER. It signs well, does it not?', 1),\n",
       " ('    State-statues only.', 1),\n",
       " ('            him over to a gaoler. Exeunt omnes', 1),\n",
       " (\"  OTHELLO. That's he that was Othello. Here I am.\", 1),\n",
       " (\"  FLEANCE. I take't 'tis later, sir.\", 1),\n",
       " (\"  SLY. Third, or fourth, or fifth borough, I'll answer him by law.\", 1),\n",
       " (\"  BOTH. Name them, my lord; let's know them.\", 1),\n",
       " ('    O, had it been a stranger, not my child,', 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.takeSample(False,10) # First parameter indicates Replacement (True) or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "##### collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'The',\n",
       " 'Complete',\n",
       " 'Works',\n",
       " 'of',\n",
       " 'William',\n",
       " 'Shakespeare,',\n",
       " 'by',\n",
       " 'William',\n",
       " 'Shakespeare',\n",
       " '',\n",
       " 'This',\n",
       " 'eBook',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'anyone',\n",
       " 'anywhere',\n",
       " 'at',\n",
       " 'no',\n",
       " 'cost',\n",
       " 'and',\n",
       " 'with',\n",
       " 'almost',\n",
       " 'no',\n",
       " 'restrictions',\n",
       " 'whatsoever.',\n",
       " '',\n",
       " 'You',\n",
       " 'may',\n",
       " 'copy',\n",
       " 'it,',\n",
       " 'give',\n",
       " 'it',\n",
       " 'away',\n",
       " 'or',\n",
       " 're-use',\n",
       " 'it',\n",
       " 'under',\n",
       " 'the',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'License',\n",
       " 'included',\n",
       " 'with',\n",
       " 'this',\n",
       " 'eBook',\n",
       " 'or',\n",
       " 'online',\n",
       " 'at',\n",
       " 'www.gutenberg.org',\n",
       " '',\n",
       " '**',\n",
       " 'This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'COPYRIGHTED',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'eBook,',\n",
       " 'Details',\n",
       " 'Below',\n",
       " '**',\n",
       " '**',\n",
       " 'This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'COPYRIGHTED',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'eBook,',\n",
       " 'Details',\n",
       " 'Below',\n",
       " '**',\n",
       " '**',\n",
       " 'This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'COPYRIGHTED',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'eBook,',\n",
       " 'Details',\n",
       " 'Below',\n",
       " '**',\n",
       " '**',\n",
       " 'This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'COPYRIGHTED',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'eBook,',\n",
       " 'Details',\n",
       " 'Below',\n",
       " '**',\n",
       " '**',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Please',\n",
       " 'follow',\n",
       " 'the',\n",
       " 'copyright',\n",
       " 'guidelines',\n",
       " 'in',\n",
       " 'this',\n",
       " 'file.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '**',\n",
       " '',\n",
       " 'Title:',\n",
       " 'The',\n",
       " 'Complete',\n",
       " 'Works',\n",
       " 'of',\n",
       " 'William',\n",
       " 'Shakespeare',\n",
       " 'The',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'EBook',\n",
       " 'of',\n",
       " 'The',\n",
       " 'Complete',\n",
       " 'Works',\n",
       " 'of',\n",
       " 'William',\n",
       " 'Shakespeare,',\n",
       " 'by',\n",
       " 'Author:',\n",
       " 'William',\n",
       " 'Shakespeare',\n",
       " '',\n",
       " 'Posting',\n",
       " 'Date:',\n",
       " 'September',\n",
       " '1,',\n",
       " '2011',\n",
       " '[EBook',\n",
       " '#100]',\n",
       " 'Release',\n",
       " 'Date:',\n",
       " 'January,',\n",
       " '1994',\n",
       " '',\n",
       " 'Language:',\n",
       " 'English',\n",
       " '',\n",
       " '',\n",
       " '***',\n",
       " 'START',\n",
       " 'OF',\n",
       " 'THIS',\n",
       " 'PROJECT',\n",
       " 'GUTENBERG',\n",
       " 'EBOOK',\n",
       " 'COMPLETE',\n",
       " 'WORKS--WILLIAM',\n",
       " 'SHAKESPEARE',\n",
       " '***',\n",
       " '',\n",
       " 're-use',\n",
       " 'it',\n",
       " 'under',\n",
       " 'the',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'License',\n",
       " 'included',\n",
       " '',\n",
       " '',\n",
       " 'Produced',\n",
       " 'by',\n",
       " 'World',\n",
       " 'Library,',\n",
       " 'Inc.,',\n",
       " 'from',\n",
       " 'their',\n",
       " 'Library',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Future',\n",
       " '',\n",
       " 're-use',\n",
       " 'it',\n",
       " 'under',\n",
       " 'the',\n",
       " 'terms',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'License',\n",
       " 'included',\n",
       " '',\n",
       " '',\n",
       " 'This',\n",
       " 'is',\n",
       " 'the',\n",
       " '100th',\n",
       " 'Etext',\n",
       " 'file',\n",
       " 'presented',\n",
       " 'by',\n",
       " 'Project',\n",
       " 'Gutenberg,',\n",
       " 'and',\n",
       " 'is',\n",
       " 'presented',\n",
       " 'in',\n",
       " 'cooperation',\n",
       " 'with',\n",
       " 'World',\n",
       " 'Library,',\n",
       " 'Inc.,',\n",
       " 'from',\n",
       " 'their',\n",
       " 'Library',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Future',\n",
       " 'and',\n",
       " 'Shakespeare',\n",
       " 'CDROMS.',\n",
       " '',\n",
       " 'Project',\n",
       " 'Gutenberg',\n",
       " 'often',\n",
       " 'releases',\n",
       " 'Etexts',\n",
       " 'that',\n",
       " 'are',\n",
       " 'NOT',\n",
       " 'placed',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Public',\n",
       " 'Domain!!',\n",
       " '',\n",
       " 'Shakespeare',\n",
       " '',\n",
       " '*This',\n",
       " 'Etext',\n",
       " 'has',\n",
       " 'certain',\n",
       " 'copyright',\n",
       " 'implications',\n",
       " 'you',\n",
       " 'should',\n",
       " 'read!*',\n",
       " '',\n",
       " '<<THIS',\n",
       " 'ELECTRONIC',\n",
       " 'VERSION',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'COMPLETE',\n",
       " 'WORKS',\n",
       " 'OF',\n",
       " 'WILLIAM',\n",
       " 'SHAKESPEARE',\n",
       " 'IS',\n",
       " 'COPYRIGHT',\n",
       " '1990-1993',\n",
       " 'BY',\n",
       " 'WORLD',\n",
       " 'LIBRARY,',\n",
       " 'INC.,',\n",
       " 'AND',\n",
       " 'IS',\n",
       " 'PROVIDED',\n",
       " 'BY',\n",
       " 'PROJECT',\n",
       " 'GUTENBERG',\n",
       " 'ETEXT',\n",
       " 'OF',\n",
       " 'ILLINOIS',\n",
       " 'BENEDICTINE',\n",
       " 'COLLEGE',\n",
       " 'WITH',\n",
       " 'PERMISSION.',\n",
       " '',\n",
       " 'ELECTRONIC',\n",
       " 'AND',\n",
       " 'MACHINE',\n",
       " 'READABLE',\n",
       " 'COPIES',\n",
       " 'MAY',\n",
       " 'BE',\n",
       " 'DISTRIBUTED',\n",
       " 'SO',\n",
       " 'LONG',\n",
       " 'AS',\n",
       " 'SUCH',\n",
       " 'COPIES',\n",
       " '(1)',\n",
       " 'ARE',\n",
       " 'FOR',\n",
       " 'YOUR',\n",
       " 'OR',\n",
       " 'OTHERS',\n",
       " 'PERSONAL',\n",
       " 'USE',\n",
       " 'ONLY,',\n",
       " 'AND',\n",
       " '(2)',\n",
       " 'ARE',\n",
       " 'NOT',\n",
       " 'DISTRIBUTED',\n",
       " 'OR',\n",
       " 'USED',\n",
       " 'COMMERCIALLY.',\n",
       " '',\n",
       " 'PROHIBITED',\n",
       " 'COMMERCIAL',\n",
       " 'DISTRIBUTION',\n",
       " 'INCLUDES',\n",
       " 'BY',\n",
       " 'ANY',\n",
       " 'SERVICE',\n",
       " 'THAT',\n",
       " 'CHARGES',\n",
       " 'FOR',\n",
       " 'DOWNLOAD',\n",
       " 'TIME',\n",
       " 'OR',\n",
       " 'FOR',\n",
       " 'MEMBERSHIP.>>',\n",
       " '',\n",
       " '*Project',\n",
       " 'Gutenberg',\n",
       " 'is',\n",
       " 'proud',\n",
       " 'to',\n",
       " 'cooperate',\n",
       " 'with',\n",
       " 'The',\n",
       " 'World',\n",
       " 'Library*',\n",
       " 'in',\n",
       " 'the',\n",
       " 'presentation',\n",
       " 'of',\n",
       " 'The',\n",
       " 'Complete',\n",
       " 'Works',\n",
       " 'of',\n",
       " 'William',\n",
       " 'Shakespeare',\n",
       " 'for',\n",
       " 'your',\n",
       " 'reading',\n",
       " 'for',\n",
       " 'education',\n",
       " 'and',\n",
       " 'entertainment.',\n",
       " '',\n",
       " 'HOWEVER,',\n",
       " 'THIS',\n",
       " 'IS',\n",
       " 'NEITHER',\n",
       " 'SHAREWARE',\n",
       " 'NOR',\n",
       " 'PUBLIC',\n",
       " 'DOMAIN.',\n",
       " '.',\n",
       " '.AND',\n",
       " 'UNDER',\n",
       " 'THE',\n",
       " 'LIBRARY',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'FUTURE',\n",
       " 'CONDITIONS',\n",
       " 'OF',\n",
       " 'THIS',\n",
       " 'PRESENTATION.',\n",
       " '.',\n",
       " '.NO',\n",
       " 'CHARGES',\n",
       " 'MAY',\n",
       " 'BE',\n",
       " 'MADE',\n",
       " 'FOR',\n",
       " '*ANY*',\n",
       " 'ACCESS',\n",
       " 'TO',\n",
       " 'THIS',\n",
       " 'MATERIAL.',\n",
       " '',\n",
       " 'YOU',\n",
       " 'ARE',\n",
       " 'ENCOURAGED!!',\n",
       " 'TO',\n",
       " 'GIVE',\n",
       " 'IT',\n",
       " 'AWAY',\n",
       " 'TO',\n",
       " 'ANYONE',\n",
       " 'YOU',\n",
       " 'LIKE,',\n",
       " 'BUT',\n",
       " 'NO',\n",
       " 'CHARGES',\n",
       " 'ARE',\n",
       " 'ALLOWED!!',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '*****',\n",
       " 'SMALL',\n",
       " 'PRINT!',\n",
       " 'for',\n",
       " 'COMPLETE',\n",
       " 'SHAKESPEARE',\n",
       " '*****',\n",
       " '',\n",
       " 'THIS',\n",
       " 'ELECTRONIC',\n",
       " 'VERSION',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'COMPLETE',\n",
       " 'WORKS',\n",
       " 'OF',\n",
       " 'WILLIAM',\n",
       " 'SHAKESPEARE',\n",
       " 'IS',\n",
       " 'COPYRIGHT',\n",
       " '1990-1993',\n",
       " 'BY',\n",
       " 'WORLD',\n",
       " 'LIBRARY,',\n",
       " 'INC.,',\n",
       " 'AND',\n",
       " 'IS',\n",
       " 'PROVIDED',\n",
       " 'BY',\n",
       " 'PROJECT',\n",
       " 'GUTENBERG',\n",
       " 'ETEXT',\n",
       " 'OF',\n",
       " 'ILLINOIS',\n",
       " 'BENEDICTINE',\n",
       " 'COLLEGE',\n",
       " 'WITH',\n",
       " 'PERMISSION.',\n",
       " '',\n",
       " 'Since',\n",
       " 'unlike',\n",
       " 'many',\n",
       " 'other',\n",
       " 'Project',\n",
       " 'Gutenberg-tm',\n",
       " 'etexts,',\n",
       " 'this',\n",
       " 'etext',\n",
       " 'is',\n",
       " 'copyright',\n",
       " 'protected,',\n",
       " 'and',\n",
       " 'since',\n",
       " 'the',\n",
       " 'materials',\n",
       " 'and',\n",
       " 'methods',\n",
       " 'you',\n",
       " 'use',\n",
       " 'will',\n",
       " 'effect',\n",
       " 'the',\n",
       " \"Project's\",\n",
       " 'reputation,',\n",
       " 'your',\n",
       " 'right',\n",
       " 'to',\n",
       " 'copy',\n",
       " 'and',\n",
       " 'distribute',\n",
       " 'it',\n",
       " 'is',\n",
       " 'limited',\n",
       " 'by',\n",
       " 'the',\n",
       " 'copyright',\n",
       " 'and',\n",
       " 'other',\n",
       " 'laws,',\n",
       " 'and',\n",
       " 'by',\n",
       " 'the',\n",
       " 'conditions',\n",
       " 'of',\n",
       " 'this',\n",
       " '\"Small',\n",
       " 'Print!\"',\n",
       " 'statement.',\n",
       " '',\n",
       " '1.',\n",
       " '',\n",
       " 'LICENSE',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'A)',\n",
       " 'YOU',\n",
       " 'MAY',\n",
       " '(AND',\n",
       " 'ARE',\n",
       " 'ENCOURAGED)',\n",
       " 'TO',\n",
       " 'DISTRIBUTE',\n",
       " 'ELECTRONIC',\n",
       " 'AND',\n",
       " 'MACHINE',\n",
       " 'READABLE',\n",
       " 'COPIES',\n",
       " 'OF',\n",
       " 'THIS',\n",
       " 'ETEXT,',\n",
       " 'SO',\n",
       " 'LONG',\n",
       " 'AS',\n",
       " 'SUCH',\n",
       " 'COPIES',\n",
       " '(1)',\n",
       " 'ARE',\n",
       " 'FOR',\n",
       " 'YOUR',\n",
       " 'OR',\n",
       " 'OTHERS',\n",
       " 'PERSONAL',\n",
       " 'USE',\n",
       " 'ONLY,',\n",
       " 'AND',\n",
       " '(2)',\n",
       " 'ARE',\n",
       " 'NOT',\n",
       " 'DISTRIBUTED',\n",
       " 'OR',\n",
       " 'USED',\n",
       " 'COMMERCIALLY.',\n",
       " '',\n",
       " 'PROHIBITED',\n",
       " 'COMMERCIAL',\n",
       " 'DISTRIBUTION',\n",
       " 'INCLUDES',\n",
       " 'BY',\n",
       " 'ANY',\n",
       " 'SERVICE',\n",
       " 'THAT',\n",
       " 'CHARGES',\n",
       " 'FOR',\n",
       " 'DOWNLOAD',\n",
       " 'TIME',\n",
       " 'OR',\n",
       " 'FOR',\n",
       " 'MEMBERSHIP.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'B)',\n",
       " 'This',\n",
       " 'license',\n",
       " 'is',\n",
       " 'subject',\n",
       " 'to',\n",
       " 'the',\n",
       " 'conditions',\n",
       " 'that',\n",
       " 'you',\n",
       " 'honor',\n",
       " 'the',\n",
       " 'refund',\n",
       " 'and',\n",
       " 'replacement',\n",
       " 'provisions',\n",
       " 'of',\n",
       " 'this',\n",
       " '\"small',\n",
       " 'print!\"',\n",
       " 'statement;',\n",
       " 'and',\n",
       " 'that',\n",
       " 'you',\n",
       " 'distribute',\n",
       " 'exact',\n",
       " 'copies',\n",
       " 'of',\n",
       " 'this',\n",
       " 'etext,',\n",
       " 'including',\n",
       " 'this',\n",
       " 'Small',\n",
       " 'Print',\n",
       " 'statement.',\n",
       " '',\n",
       " 'Such',\n",
       " 'copies',\n",
       " 'can',\n",
       " 'be',\n",
       " 'compressed',\n",
       " 'or',\n",
       " 'any',\n",
       " 'proprietary',\n",
       " 'form',\n",
       " '(including',\n",
       " 'any',\n",
       " 'form',\n",
       " 'resulting',\n",
       " 'from',\n",
       " 'word',\n",
       " 'processing',\n",
       " 'or',\n",
       " 'hypertext',\n",
       " 'software),',\n",
       " 'so',\n",
       " 'long',\n",
       " 'as',\n",
       " '*EITHER*:',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '(1)',\n",
       " 'The',\n",
       " 'etext,',\n",
       " 'when',\n",
       " 'displayed,',\n",
       " 'is',\n",
       " 'clearly',\n",
       " 'readable,',\n",
       " 'and',\n",
       " 'does',\n",
       " '',\n",
       " '',\n",
       " '*not*',\n",
       " 'contain',\n",
       " 'characters',\n",
       " 'other',\n",
       " 'than',\n",
       " 'those',\n",
       " 'intended',\n",
       " 'by',\n",
       " 'the',\n",
       " '',\n",
       " '',\n",
       " 'author',\n",
       " 'of',\n",
       " 'the',\n",
       " 'work,',\n",
       " 'although',\n",
       " 'tilde',\n",
       " '(~),',\n",
       " 'asterisk',\n",
       " '(*)',\n",
       " 'and',\n",
       " '',\n",
       " '',\n",
       " 'underline',\n",
       " '(_)',\n",
       " 'characters',\n",
       " 'may',\n",
       " 'be',\n",
       " 'used',\n",
       " 'to',\n",
       " 'convey',\n",
       " 'punctuation',\n",
       " '',\n",
       " '',\n",
       " 'intended',\n",
       " 'by',\n",
       " 'the',\n",
       " 'author,',\n",
       " 'and',\n",
       " 'additional',\n",
       " 'characters',\n",
       " 'may',\n",
       " 'be',\n",
       " 'used',\n",
       " '',\n",
       " '',\n",
       " 'to',\n",
       " 'indicate',\n",
       " 'hypertext',\n",
       " 'links;',\n",
       " 'OR',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '(2)',\n",
       " 'The',\n",
       " 'etext',\n",
       " 'is',\n",
       " 'readily',\n",
       " 'convertible',\n",
       " 'by',\n",
       " 'the',\n",
       " 'reader',\n",
       " 'at',\n",
       " 'no',\n",
       " '',\n",
       " '',\n",
       " 'expense',\n",
       " 'into',\n",
       " 'plain',\n",
       " 'ASCII,',\n",
       " 'EBCDIC',\n",
       " 'or',\n",
       " 'equivalent',\n",
       " 'form',\n",
       " 'by',\n",
       " 'the',\n",
       " '',\n",
       " '',\n",
       " 'program',\n",
       " 'that',\n",
       " 'displays',\n",
       " 'the',\n",
       " 'etext',\n",
       " '(as',\n",
       " 'is',\n",
       " 'the',\n",
       " 'case,',\n",
       " 'for',\n",
       " 'instance,',\n",
       " '',\n",
       " '',\n",
       " 'with',\n",
       " 'most',\n",
       " 'word',\n",
       " 'processors);',\n",
       " 'OR',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '(3)',\n",
       " 'You',\n",
       " 'provide',\n",
       " 'or',\n",
       " 'agree',\n",
       " 'to',\n",
       " 'provide',\n",
       " 'on',\n",
       " 'request',\n",
       " 'at',\n",
       " 'no',\n",
       " '',\n",
       " '',\n",
       " 'additional',\n",
       " 'cost,',\n",
       " 'fee',\n",
       " 'or',\n",
       " 'expense,',\n",
       " 'a',\n",
       " 'copy',\n",
       " 'of',\n",
       " 'the',\n",
       " 'etext',\n",
       " 'in',\n",
       " 'plain',\n",
       " '',\n",
       " '',\n",
       " 'ASCII.',\n",
       " '',\n",
       " '2.',\n",
       " '',\n",
       " 'LIMITED',\n",
       " 'WARRANTY;',\n",
       " 'DISCLAIMER',\n",
       " 'OF',\n",
       " 'DAMAGES',\n",
       " '',\n",
       " 'This',\n",
       " 'etext',\n",
       " 'may',\n",
       " 'contain',\n",
       " 'a',\n",
       " '\"Defect\"',\n",
       " 'in',\n",
       " 'the',\n",
       " 'form',\n",
       " 'of',\n",
       " 'incomplete,',\n",
       " 'inaccurate',\n",
       " 'or',\n",
       " 'corrupt',\n",
       " 'data,',\n",
       " 'transcription',\n",
       " 'errors,',\n",
       " 'a',\n",
       " 'copyright',\n",
       " 'or',\n",
       " 'other',\n",
       " 'infringement,',\n",
       " 'a',\n",
       " 'defective',\n",
       " 'or',\n",
       " 'damaged',\n",
       " 'disk,',\n",
       " 'computer',\n",
       " 'virus,',\n",
       " 'or',\n",
       " 'codes',\n",
       " 'that',\n",
       " 'damage',\n",
       " 'or',\n",
       " 'cannot',\n",
       " 'be',\n",
       " 'read',\n",
       " 'by',\n",
       " 'your',\n",
       " 'equipment.',\n",
       " '',\n",
       " 'But',\n",
       " 'for',\n",
       " 'the',\n",
       " '\"Right',\n",
       " 'of',\n",
       " 'Replacement',\n",
       " 'or',\n",
       " 'Refund\"',\n",
       " 'described',\n",
       " 'below,',\n",
       " 'the',\n",
       " 'Project',\n",
       " '(and',\n",
       " 'any',\n",
       " 'other',\n",
       " 'party',\n",
       " 'you',\n",
       " 'may',\n",
       " 'receive',\n",
       " 'this',\n",
       " 'etext',\n",
       " 'from',\n",
       " 'as',\n",
       " 'a',\n",
       " 'PROJECT',\n",
       " 'GUTENBERG-tm',\n",
       " 'etext)',\n",
       " 'disclaims',\n",
       " 'all',\n",
       " 'liability',\n",
       " 'to',\n",
       " 'you',\n",
       " 'for',\n",
       " 'damages,',\n",
       " 'costs',\n",
       " 'and',\n",
       " 'expenses,',\n",
       " 'including',\n",
       " 'legal',\n",
       " 'fees,',\n",
       " 'and',\n",
       " 'YOU',\n",
       " 'HAVE',\n",
       " 'NO',\n",
       " 'REMEDIES',\n",
       " 'FOR',\n",
       " 'NEGLIGENCE',\n",
       " 'OR',\n",
       " 'UNDER',\n",
       " 'STRICT',\n",
       " 'LIABILITY,',\n",
       " 'OR',\n",
       " 'FOR',\n",
       " 'BREACH',\n",
       " 'OF',\n",
       " 'WARRANTY',\n",
       " 'OR',\n",
       " 'CONTRACT,',\n",
       " 'INCLUDING',\n",
       " 'BUT',\n",
       " 'NOT',\n",
       " 'LIMITED',\n",
       " 'TO',\n",
       " 'INDIRECT,',\n",
       " 'CONSEQUENTIAL,',\n",
       " 'PUNITIVE',\n",
       " 'OR',\n",
       " 'INCIDENTAL',\n",
       " 'DAMAGES,',\n",
       " 'EVEN',\n",
       " 'IF',\n",
       " 'YOU',\n",
       " 'GIVE',\n",
       " 'NOTICE',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'POSSIBILITY',\n",
       " 'OF',\n",
       " 'SUCH',\n",
       " 'DAMAGES.',\n",
       " '',\n",
       " 'If',\n",
       " 'you',\n",
       " 'discover',\n",
       " 'a',\n",
       " 'Defect',\n",
       " 'in',\n",
       " 'this',\n",
       " 'etext',\n",
       " 'within',\n",
       " '90',\n",
       " 'days',\n",
       " 'of',\n",
       " 'receiv-',\n",
       " 'ing',\n",
       " 'it,',\n",
       " 'you',\n",
       " 'can',\n",
       " 'receive',\n",
       " 'a',\n",
       " 'refund',\n",
       " 'of',\n",
       " 'the',\n",
       " 'money',\n",
       " '(if',\n",
       " 'any)',\n",
       " 'you',\n",
       " 'paid',\n",
       " 'for',\n",
       " 'it',\n",
       " 'by',\n",
       " 'sending',\n",
       " 'an',\n",
       " 'explanatory',\n",
       " 'note',\n",
       " 'within',\n",
       " 'that',\n",
       " 'time',\n",
       " 'to',\n",
       " 'the',\n",
       " 'person',\n",
       " 'you',\n",
       " 'received',\n",
       " 'it',\n",
       " 'from.',\n",
       " '',\n",
       " 'If',\n",
       " 'you',\n",
       " 'received',\n",
       " 'it',\n",
       " 'on',\n",
       " 'a',\n",
       " 'physical',\n",
       " 'medium,',\n",
       " 'you',\n",
       " 'must',\n",
       " 'return',\n",
       " 'it',\n",
       " 'with',\n",
       " 'your',\n",
       " 'note,',\n",
       " 'and',\n",
       " 'such',\n",
       " 'person',\n",
       " 'may',\n",
       " 'choose',\n",
       " 'to',\n",
       " 'alternatively',\n",
       " 'give',\n",
       " 'you',\n",
       " 'a',\n",
       " 'replacement',\n",
       " 'copy.',\n",
       " '',\n",
       " 'If',\n",
       " 'you',\n",
       " 'received',\n",
       " 'it',\n",
       " 'electronically,',\n",
       " 'such',\n",
       " 'person',\n",
       " 'may',\n",
       " 'choose',\n",
       " ...]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shakespeareWords = Shakespeare.flatMap(lambda x: x.split(' '))\n",
    "shakespeareWords.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "##### count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1410735"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeareWords.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "##### reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conjunto2RDD = sc.parallelize([2, 3, 4, 5])\n",
    "conjunto2RDD.reduce(lambda a, n: a + n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "##### takeOrdered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 5, 5, 7]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conjunto3RDD = sc.parallelize([8,7,5,4,1,1,7,2,5])\n",
    "# conjunto3filtrado = conjunto3RDD.filter(lambda x:x>1)\n",
    "conjunto3filtrado.takeOrdered(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### Writing RDDs into external files\n",
    "1. **saveAsTextFile(path)**\n",
    "2. **saveAsSequenceFile(path)** (Previously explained)\n",
    "3. **saveAsObjectFile(path)** (Only for Java and Scala)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeareWords.saveAsTextFile(\"../data/PalabrasShakespeare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos los directorios previamente creados.\n",
    "import shutil\n",
    "shutil.rmtree(\"../data/PalabrasShakespeare\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## 4 · RDD Persistance\n",
    "One of the most important capabilities in Spark is **persisting (or caching)** a dataset in memory across operations. When you persist an RDD, each node stores any partitions of it that it computes in memory and reuses them in other actions on that dataset (or datasets derived from it). This allows future actions to be much faster (often by more than 10x). Caching is a key tool for iterative algorithms and fast interactive use.  \n",
    "\n",
    "You can mark an RDD to be persisted using the **persist()** or **cache()** methods on it. In addition, each persisted RDD can be stored using a different storage level, allowing you, for example, to persist the dataset on disk, persist it in memory but as serialized Java objects (to save space), replicate it across nodes. These levels are set by passing a StorageLevel object to persist(). \n",
    "The cache() method is a shorthand for using the default storage level, which is StorageLevel.MEMORY_ONLY (store deserialized objects in memory).\n",
    "For more information, you can visit https://spark.apache.org/docs/latest/rdd-programming-guide.html.  \n",
    "\n",
    "Spark automatically monitors cache usage on each node and drops out old data partitions in a least-recently-used (LRU) fashion. If you would like to manually remove an RDD instead of waiting for it to fall out of the cache, use the RDD.unpersist() method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## 5 · Shared Variables · Cluster Computing\n",
    "To execute jobs, Spark **breaks up the processing of RDD operations into tasks**, each of which is **executed by an executor**. Prior to execution, Spark computes the task’s closure. The ***closure is those variables and methods which must be visible for the executor to perform its computations on the RDD***. This closure is serialized and sent to each executor.  \n",
    "\n",
    "The variables within the closure sent to each executor are now **copies** and thus, those variables **are not longer the variables on the driver node** and no updates to the variables on the remote machine are propagated back to the driver program. Supporting general, read-write shared variables across tasks would be inefficient. However, Spark does provide two limited types of shared variables for two common usage patterns: **broadcast variables** and **accumulators**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter value:  0\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "data = [1,5,7,8,9,10,2,41,5]\n",
    "rdd = sc.parallelize(data)\n",
    "\n",
    "# Wrong: El contador no se actualizará!\n",
    "def increment_counter(x):\n",
    "    global counter\n",
    "    counter += x\n",
    "\n",
    "rdd.foreach(increment_counter)\n",
    "print(\"Counter value: \", counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Broadcast\n",
    "Broadcast variables allow the programmer to keep a read-only variable cached on each machine rather than shipping a copy of it with tasks. Their main features are:\n",
    "* **Immutable**, they cannot be changed later on.\n",
    "* Have to be able to **fit in memory** on one machine. That means that they definitely should NOT be anything super large.\n",
    "* **Distributed to the cluster**\n",
    "  \n",
    "e.g. Reference table which is compared with other data several times during the application execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'bye', 2: 'adiós', 3: 'ciao'}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Var = sc.parallelize([(1,\"bye\"), (2,\"adiós\"), (3,\"ciao\")]).collectAsMap()\n",
    "broadcastVar = sc.broadcast(Var)\n",
    "broadcastVar.value\n",
    "# Se puede comprobar que no existe el método collect() para este tipo de variables,\n",
    "# ya que no está repartido entre las máquinas del cluster "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Accumulators\n",
    "Accumulators are variables that are only “added” to through an associative and commutative operation and can therefore be efficiently supported in parallel. They can be used to implement counters or sums. Spark natively supports accumulators of numeric types, and programmers can add support for new types.\n",
    "  \n",
    "Integer and float accumulator examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accumulator<id=3, value=0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accum = sc.accumulator(0)\n",
    "accum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([1, 2, 3, 4]).foreach(lambda x: accum.add(x))\n",
    "accum.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "programmers can add support for new types by subclassing ***AccumulatorParam*** class.\n",
    "This class has two methods:\n",
    "1. **zero**: It provides a \"zero value\" to the new accumulator type.\n",
    "2. **addInPlace**: It indicates the way two values are added.\n",
    "  \n",
    "Vector-type accumulator example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default AccumulatorParams are used for integers and floating-point numbers if you do not provide one. \n",
    "# For other types, a custom AccumulatorParam can be used.\n",
    "# accumulator(value, accum_param=None)\n",
    "\n",
    "# Then, create an Accumulator of this type:\n",
    "# vecAccum = sc.accumulator(Vector(...), VectorAccumulatorParam())\n",
    "\n",
    "from pyspark.accumulators import AccumulatorParam\n",
    "class VectorAccumulatorParam(AccumulatorParam):\n",
    "    def zero(self, value):\n",
    "        return [0.0] * len(value)\n",
    "    def addInPlace(self, val1, val2):\n",
    "        for i in xrange(len(val1)):\n",
    "            val1[i] += val2[i]\n",
    "        return val1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "For accumulator updates performed inside ***actions*** only, Spark guarantees that **each task’s update to the accumulator will only be applied once**, i.e. restarted tasks will not update the value. In ***transformations***, users should be aware of that **each task’s update may be applied more than once if tasks or job stages are re-executed**.\n",
    "\n",
    "Accumulators do not change the lazy evaluation model of Spark. If they are being updated within an operation on an RDD, **their value is only updated once that RDD is computed as part of an action**. Consequently, accumulator updates are not guaranteed to be executed when made within a lazy transformation like map()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "distributedData = sc.parallelize([2,85,6,4,8,9,6,1,0])\n",
    "accum = sc.accumulator(0)\n",
    "def g(x):\n",
    "    accum.add(x)\n",
    "    return f(x)\n",
    "distributedData.map(g)\n",
    "print(accum)\n",
    "# accum todavía vale 0 ya que no hay ninguna acción lanzada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## 6 · Application Deployment to a cluster\n",
    "The spark-submit script in Spark’s bin directory is used to launch applications on a cluster. It can use all of Spark’s supported cluster managers through a uniform interface so you don’t have to configure your application especially for each one.  \n",
    "\n",
    "If your code depends on other projects, you will need to package them alongside your application in order to distribute the code to a Spark cluster. To do this, use the **--py-files** argument of spark-submit to add .py, .zip or .egg files to be distributed with your application. If you depend on multiple Python files we recommend packaging them into a .zip or .egg.\n",
    "#### Deployment examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run application locally on 8 cores\n",
    "./bin/spark-submit \\\n",
    "  --class org.apache.spark.examples.SparkPi \\\n",
    "  --master local[8] \\\n",
    "  /path/to/examples.jar \\\n",
    "  100\n",
    "\n",
    "# Run on a Spark standalone cluster in client deploy mode\n",
    "./bin/spark-submit \\\n",
    "  --class org.apache.spark.examples.SparkPi \\\n",
    "  --master spark://207.184.161.138:7077 \\\n",
    "  --executor-memory 20G \\\n",
    "  --total-executor-cores 100 \\\n",
    "  /path/to/examples.jar \\\n",
    "  1000\n",
    "\n",
    "# Run on a Spark standalone cluster in cluster deploy mode with supervise\n",
    "./bin/spark-submit \\\n",
    "  --class org.apache.spark.examples.SparkPi \\\n",
    "  --master spark://207.184.161.138:7077 \\\n",
    "  --deploy-mode cluster \\\n",
    "  --supervise \\\n",
    "  --executor-memory 20G \\\n",
    "  --total-executor-cores 100 \\\n",
    "  /path/to/examples.jar \\Hola \n",
    "  1000\n",
    "\n",
    "# Run on a YARN cluster\n",
    "export HADOOP_CONF_DIR=XXX\n",
    "./bin/spark-submit \\\n",
    "  --class org.apache.spark.examples.SparkPi \\\n",
    "  --master Finalizamosyarn \\\n",
    "  --deploy-mode cluster \\  # can be client for client mode\n",
    "  --executor-memory 20G \\\n",
    "  --num-executors 50 \\\n",
    "  /path/to/examples.jar \\\n",
    "  1000\n",
    "\n",
    "# Run a Python application on a Spark standalone cluster\n",
    "./bin/spark-submit \\\n",
    "  --master spark://207.184.161.138:7077 \\\n",
    "  examples/src/main/python/pi.py \\\n",
    "  1000\n",
    "\n",
    "# Run on a Mesos cluster in cluster deploy mode with supervise\n",
    "./bin/spark-submit \\\n",
    "  --class org.apache.spark.examples.SparkPi \\\n",
    "  --master mesos://207.184.161.138:7077 \\\n",
    "  --deploy-mode cluster \\\n",
    "  --supervise \\\n",
    "  --executor-memory 20G \\\n",
    "  --total-executor-cores 100 \\\n",
    "  http://path/to/examples.jar \\\n",
    "  1000Session\n",
    "\n",
    "# Run on a Kubernetes cluster in cluster deploy mode\n",
    "./bin/spark-submit \\\n",
    "  --class org.apache.spark.examples.SparkPi \\\n",
    "  --master k8s://xx.yy.zz.ww:443 \\\n",
    "  --deploy-mode cluster \\\n",
    "  --executor-memory 20G \\\n",
    "  --num-executors 50 \\\n",
    "  http://path/to/examples.jar \\\n",
    "  1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## 7 · Stop Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
